{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380f9403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import tensorflow as tf\n",
    "import sys\n",
    "import csv\n",
    "import random\n",
    "import os\n",
    "from io import StringIO\n",
    "import keras\n",
    "from keras.layers import Input, Dense, concatenate, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sparsemax import Sparsemax\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,roc_curve\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01852fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Define how you want to encode ##########################\n",
    "\n",
    "#The path used to get the HLA dictionary：\n",
    "aa_dict_dir='../library/Atchley_factors.csv'\n",
    "hla_db_dir='../library/hla_library'\n",
    "aa_list = [letter for letter in 'ARNDCEQGHILKMFPSTWYV']\n",
    "aa_to_idx_dict = {aa: idx+1 for idx, aa in enumerate(aa_list)}\n",
    "aa_dict = {aa: idx+1 for idx, aa in enumerate(aa_list)}\n",
    "\n",
    "pca15_aaidx = {\n",
    "    'A': np.array([\n",
    "        -0.97090603, -0.32368135, 15.72065182, -0.50884066,  3.74021858,\n",
    "        -0.77879681,  3.38667656, -0.91306275,  3.00614751, -2.32919906,\n",
    "         0.7870219 , -1.87437966,  1.53335388,  1.344461  ,  3.35815929]),\n",
    "    'R': np.array([\n",
    "         8.53814625, -13.78745836,  -4.7706284 ,  -1.16449378,\n",
    "        -9.46561383,   6.79244266,   1.98971004,  -5.15274046,\n",
    "        -2.93772088,  -5.89206951,   5.26993696,   1.61036613,\n",
    "        -1.95208183,  -0.64409   ,   1.53934309]),\n",
    "    'N': np.array([\n",
    "        14.86976088,  1.57062419, -3.62321751,  5.63672398, -1.78396131,\n",
    "        -3.62736822, -1.44652457,  5.39945262,  0.87616878,  4.1128776 ,\n",
    "         1.91381611,  2.4206327 , -3.81386422, -5.242596  ,  3.97131233]),\n",
    "    'D': np.array([\n",
    "        18.12626589, -2.14738155, -0.25216984,  2.31366107,  6.52406372,\n",
    "        -4.88386469, -9.13828094, -0.71024376, -2.10295526, -1.27865374,\n",
    "         1.48217398,  1.43032329, -4.04631611,  5.72388976, -1.78674913]),\n",
    "    'C': np.array([\n",
    "        -8.36918251e+00,  8.30319345e+00, -6.61966946e+00,  1.38734140e+01,\n",
    "         8.59531324e+00,  9.79914818e+00,  1.26911187e+00, -4.63752901e+00,\n",
    "        -9.83921566e-01,  4.36342436e+00,  2.34365256e+00,  3.43445840e-01,\n",
    "         1.18290876e+00,  1.32558804e-02, -6.96621503e-01]),\n",
    "    'E': np.array([\n",
    "        12.03159874, -13.30121908,   8.27995382,  -2.1963886 ,\n",
    "         8.48308971,  -2.02004094,  -4.58165905,  -2.68526505,\n",
    "        -2.60424798,  -0.13228263,  -0.2394944 ,  -2.40393485,\n",
    "          4.1802745 ,  -4.40432039,   0.23979065]),\n",
    "    'Q': np.array([\n",
    "         7.9210965 , -8.69666506, -0.59701694,  0.02046296,  0.93026397,\n",
    "         2.56565474,  1.14554766,  0.50500247,  0.71467344,  0.04438606,\n",
    "        -6.00954372,  3.89329376,  2.44305793, -2.76002278, -1.6987172 ]),\n",
    "    'G': np.array([\n",
    "        14.83920873, 19.24138906,  5.93438829,  5.66738401, -5.81883134,\n",
    "        -8.78866739,  5.73914235, -4.72849218, -4.20333219, -1.56492845,\n",
    "        -1.37450169, -0.61253836,  0.6617134 , -0.69921372, -1.40639534]),\n",
    "    'H': np.array([\n",
    "         0.68805439, -6.17956596, -6.80550604,  3.94746531,  1.33297594,\n",
    "        -0.51211304,  4.73783089,  8.74722377, -3.12401236, -1.57598186,\n",
    "         1.98977266, -7.78869789,  0.99852322,  1.37575734, -0.43120018]),\n",
    "    'I': np.array([\n",
    "        -20.34084677,   4.14384693,   3.86394279,  -3.40504491,\n",
    "         -2.78992754,   1.46082574,  -4.07088528,   0.58387152,\n",
    "         -3.41337954,   1.84625632,  -3.12082912,  -1.14873131,\n",
    "         -4.65093114,  -1.64689363,   1.46078507]),\n",
    "    'L': np.array([\n",
    "        -17.63623772,  -0.35239597,  11.83924317,  -5.37540851,\n",
    "         -1.15954659,  -1.97240237,   0.8551395 ,   0.5305574 ,\n",
    "          2.1201762 ,   4.05167588,   7.06745699,   2.57547229,\n",
    "          1.4547904 ,   1.28288187,  -0.26554788]),\n",
    "    'K': np.array([\n",
    "        11.70658851, -13.64488577,   2.13621858,  -2.01605285,\n",
    "        -6.38068619,   0.81226081,   4.37857192,  -1.6496082 ,\n",
    "         1.42540472,   8.6009414 ,  -2.9141596 ,  -1.63197862,\n",
    "        -1.76542326,   2.93593542,  -2.78651305]),\n",
    "    'M': np.array([\n",
    "        -15.59654594,  -5.74596901,   1.05654898,   1.8258127 ,\n",
    "          6.65236588,  -1.21996347,   6.87749571,   2.80480871,\n",
    "         -1.90746691,  -3.59099156,  -4.0585946 ,   5.83997368,\n",
    "         -2.03857504,   2.47274257,   1.55383649]),\n",
    "    'F': np.array([\n",
    "        -18.59572859,   0.92235509,  -3.31743268,  -2.52174562,\n",
    "         -0.45125923,  -4.09153376,  -0.39932096,   2.4112244 ,\n",
    "         -1.0836413 ,  -1.47072537,   3.19432868,   2.04374527,\n",
    "          0.29441083,  -3.18840009,  -6.45603094]),\n",
    "    'P': np.array([\n",
    "        16.21704723,  15.09127036,  -8.72320617, -18.77750006,\n",
    "         6.46478124,   4.56244976,   3.05557799,   0.15690408,\n",
    "        -0.66929999,   0.7338994 ,   0.3953321 ,  -0.16512658,\n",
    "        -0.43811542,   0.05203475,   0.50555428]),\n",
    "    'S': np.array([\n",
    "        11.85274099,  6.88460214,  2.96725951,  3.6290185 , -2.88619312,\n",
    "         2.32382186, -1.33830204,  3.31676758,  6.26373175, -0.89789266,\n",
    "         0.739414  ,  1.15021805,  1.36104635,  1.13305848,  1.16395609]),\n",
    "    'T': np.array([\n",
    "         4.53029865,  5.12654936,  1.43605965,  1.7684372 , -3.39334852,\n",
    "         5.24360932, -3.36448143,  2.20062621,  6.52685307, -4.74609137,\n",
    "        -2.03988324, -0.65055289,  0.19272884, -0.25439792, -3.25573314]),\n",
    "    'W': np.array([\n",
    "        -16.29768602,  -3.90769937, -13.79255488,  -0.84325799,\n",
    "          2.33264713,  -8.04187276,   0.50186494,  -6.42108915,\n",
    "          7.2327353 ,  -1.12521691,  -1.01561524,  -3.54186466,\n",
    "         -1.9445611 ,  -0.81438463,   1.37250825]),\n",
    "    'Y': np.array([\n",
    "        -7.49926   ,   1.31004507, -12.07792238,  -1.16106141,\n",
    "        -6.8946393 ,  -3.23103968,  -4.86248111,   0.68815174,\n",
    "        -2.45473764,   1.48233974,  -1.42869414,   2.18166427,\n",
    "         7.4468281 ,   3.0783195 ,   2.84874949]),\n",
    "    'V': np.array([\n",
    "        -16.01441319,   5.49304582,   7.34505768,  -0.71258533,\n",
    "         -4.03171245,   5.60745006,  -4.73473404,  -0.44655998,\n",
    "         -2.68117513,  -0.63176764,  -2.98159019,  -3.67133046,\n",
    "         -1.09976811,   0.24198258,   0.76951331])}\n",
    "\n",
    "def enc_list_bl_max_len(aa_seqs, aa_codes, max_seq_len):\n",
    "    '''\n",
    "    aa_codes of a list of amino acid sequences with padding \n",
    "    to a max length\n",
    "\n",
    "    parameters:\n",
    "        - aa_seqs : list with AA sequences\n",
    "        - aa_codes : dictionnary: key= AA, value= aa_codes\n",
    "        - max_seq_len: common length for padding\n",
    "    returns:\n",
    "        - enc_aa_seq : list of np.ndarrays containing padded, encoded amino acid sequences\n",
    "    '''\n",
    "\n",
    "    # encode sequences:\n",
    "    sequences=[]\n",
    "    for seq in aa_seqs:\n",
    "        e_seq=np.zeros((len(seq),len(aa_codes[\"A\"])), dtype=np.int32)\n",
    "        count=0\n",
    "        for aa in seq:\n",
    "            if aa in aa_codes:\n",
    "                e_seq[count]=aa_codes[aa]\n",
    "                count+=1\n",
    "            else:\n",
    "                sys.stderr.write(\"Unknown amino acid in peptides: \"+ aa +\", encoding aborted!\\n\")\n",
    "                sys.exit(2)\n",
    "                \n",
    "        sequences.append(e_seq)\n",
    "\n",
    "    # pad sequences:\n",
    "    #max_seq_len = max([len(x) for x in aa_seqs])\n",
    "    \n",
    "    n_seqs = len(aa_seqs)\n",
    "    n_features = sequences[0].shape[1]\n",
    "\n",
    "    enc_aa_seq = np.zeros((n_seqs, max_seq_len, n_features), dtype=np.float32)\n",
    "    for i in range(0,n_seqs):\n",
    "        enc_aa_seq[i, :sequences[i].shape[0], :n_features] = sequences[i]\n",
    "\n",
    "    return enc_aa_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def5a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### HLA pseudo-sequence ##########################\n",
    "\n",
    "HLA_ABC=[hla_db_dir+'/A_prot.fasta',hla_db_dir+'/B_prot.fasta',hla_db_dir+'/C_prot.fasta',hla_db_dir+'/E_prot.fasta']\n",
    "# HLA_ABC=[hla_db_dir+'/AA.txt']\n",
    "HLA_seq_lib = {}\n",
    "\n",
    "# 遍历 HLA_ABC 中的文件路径\n",
    "for one_class in HLA_ABC:\n",
    "    with open(one_class, 'r') as prot:\n",
    "        name = ''\n",
    "        sequence = ''\n",
    "        for line in prot:\n",
    "            if line.startswith('>HLA'):\n",
    "                if name and sequence:\n",
    "                    HLA_seq_lib[name] = sequence\n",
    "                name = line.split(' ')[1]\n",
    "                sequence = ''\n",
    "            else:\n",
    "                sequence += line.strip()\n",
    "        \n",
    "        # 处理最后一个 HLA\n",
    "        if name and sequence:\n",
    "            HLA_seq_lib[name] = sequence\n",
    "\n",
    "\n",
    "def HLA_seq_list(HLA):\n",
    "    hla_list = []\n",
    "\n",
    "    for HLA_name in HLA:\n",
    "        if HLA_name not in HLA_seq_lib.keys():\n",
    "            if len([hla_allele for hla_allele in HLA_seq_lib.keys() if hla_allele.startswith(str(HLA_name))]) == 0:\n",
    "                print('cannot find' + HLA_name)\n",
    "            HLA_name = [hla_allele for hla_allele in HLA_seq_lib.keys() if hla_allele.startswith(str(HLA_name))][0]\n",
    "\n",
    "        if HLA_name not in HLA_seq_lib.keys():\n",
    "            print('Not proper HLA allele:' + HLA_name)\n",
    "\n",
    "        HLA_sequence = HLA_seq_lib[HLA_name]\n",
    "        hla_list.append(HLA_sequence)\n",
    "\n",
    "    return hla_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbfe655",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################  LSTM module ##########################\n",
    "\n",
    "class DotProductScore(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(DotProductScore, self).__init__()\n",
    "        self.q = nn.Parameter(torch.empty(size=(hidden_size, 1), dtype=torch.float32))\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        # Initialize weight range\n",
    "        initrange = 0.5\n",
    "        self.q.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            - X: Input matrix, inputs=[batch_size, seq_length, hidden_size]\n",
    "        Output:\n",
    "            - scores: Output matrix, shape=[batch_size, seq_length]\n",
    "        \"\"\"\n",
    "        # Calculate attention scores using dot product attention\n",
    "        scores = torch.matmul(inputs, self.q)\n",
    "        # Compress the last dimension of the tensor, from (batch_size, seq_length, 1) to (batch_size, seq_length)\n",
    "        scores = scores.squeeze(-1)\n",
    "        return scores\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        # Define the attention module, which includes the DotProductScore module\n",
    "        self.scores = DotProductScore(hidden_size)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        # Calculate attention scores ((batch_size, seq_length))\n",
    "        scores = self.scores(X)\n",
    "        # Generate masks to mask positions beyond valid lengths\n",
    "        arrange = torch.arange(X.size(1), dtype=torch.float32, device=X.device).unsqueeze(0)\n",
    "        mask = (arrange < valid_lens.unsqueeze(-1)).float()\n",
    "        # Set scores of invalid positions to negative infinity to make them approach zero in softmax operation\n",
    "        scores = scores * mask - (1 - mask) * 1e9  # Mask invalid positions\n",
    "        # Use softmax to get attention weights\n",
    "        attention_weights = nn.functional.softmax(scores, dim=-1)\n",
    "        # Apply attention weights to input tensor X to get the weighted average output\n",
    "        out = torch.matmul(attention_weights.unsqueeze(1), X).squeeze(1)\n",
    "        return out\n",
    "\n",
    "class ModelLSTMAttention(nn.Module):\n",
    "    def __init__(self, input_size=15, hidden_size=30, output_size=64, num_layers=2, dropout=0.4):\n",
    "        super(ModelLSTMAttention, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout, bidirectional=True)\n",
    "        # Define the attention module, where the input hidden_size needs to be multiplied by 2 because it is bidirectional\n",
    "        self.attention = Attention(hidden_size * 2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Define the final fully connected layer, the input dimension is also hidden_size * 2\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, seq, valid_lens):\n",
    "        \n",
    "        output, _ = self.lstm(seq)\n",
    "        valid_lens = valid_lens.view(-1,).to(device)\n",
    "        # Apply the attention module to get the weighted average output\n",
    "        out = self.attention(output, valid_lens)\n",
    "        \n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30927c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################  Transformer module ##########################\n",
    "\n",
    "sys.path.append(\"./python/\")\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, max_steps, max_dims, dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        if max_dims % 2 == 1: max_dims += 1\n",
    "        p, i = np.meshgrid(np.arange(max_steps), np.arange(max_dims // 2))\n",
    "        pos_emb = np.empty((1, max_steps, max_dims))\n",
    "        pos_emb[0, :,  ::2] = np.sin(p / 10000**(2 * i / max_dims)).T\n",
    "        pos_emb[0, :, 1::2] = np.cos(p / 10000**(2 * i / max_dims)).T\n",
    "        self.positional_embeddding = torch.tensor(pos_emb, dtype=dtype)\n",
    "        #positional_embeddding = torch.tensor(pos_emb, dtype=dtype)\n",
    "        #self.register_buffer('positional_embeddding', positional_embeddding)\n",
    "    def forward(self, inputs):\n",
    "        shape = inputs.shape\n",
    "        return inputs + self.positional_embeddding[:, :shape[-2], :shape[-1]]\n",
    "      \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "#         self.sparsemax = Sparsemax(dim = 1)\n",
    "        \n",
    "        assert embed_dim % self.num_heads == 0\n",
    "        self.depth = embed_dim // self.num_heads\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.depth]))\n",
    "        #scale = torch.sqrt(torch.FloatTensor([self.depth]))\n",
    "        #self.register_buffer('scale', scale)\n",
    "        self.wq = nn.Linear(embed_dim, embed_dim)\n",
    "        self.wk = nn.Linear(embed_dim, embed_dim)\n",
    "        self.wv = nn.Linear(embed_dim, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        batch_size = q.shape[0] # \n",
    "        \n",
    "        # (batch_size, seq_len, embed_dim)\n",
    "        Q = self.wq(q)  \n",
    "        K = self.wk(k)\n",
    "        V = self.wv(v)\n",
    "        \n",
    "        # (batch_size, num_heads, seq_len_q, depth) \n",
    "        Q = Q.view(batch_size, -1, self.num_heads, self.depth).permute(0,2,1,3)\n",
    "        K = K.view(batch_size, -1, self.num_heads, self.depth).permute(0,2,1,3)\n",
    "        V = V.view(batch_size, -1, self.num_heads, self.depth).permute(0,2,1,3)\n",
    "        \n",
    "        attention = torch.matmul(Q, K.permute(0,1,3,2)) / self.scale.to(device)\n",
    "        \n",
    "        \n",
    " \n",
    "        \n",
    "        if mask is not None:\n",
    "            attention = attention.masked_fill(mask==0, -1e10)\n",
    "        attention = torch.softmax(attention, dim=-1).to(device)\n",
    "        \n",
    "        x = torch.matmul(attention, V)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous() # (batch_size, seq_len_q, num_heads, depth)\n",
    "        x = x.view(batch_size, -1, self.embed_dim) # (batch_size, seq_len, embed_dim)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "      \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(embed_dim, num_heads).to(device)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, embed_dim)\n",
    "        )\n",
    "        self.layernorm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layernorm2 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(rate)\n",
    "        self.dropout2 = nn.Dropout(rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.mha(x,x,x)\n",
    "        out1 = self.dropout1(out1)\n",
    "        out1 = self.layernorm1(x+out1)\n",
    "        out2 = self.ffn(out1)\n",
    "        out2 = self.dropout2(out2)\n",
    "        out2 = self.layernorm2(out1+out2)\n",
    "        return out2\n",
    "class TokAndPosEmbedding(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len=9, voc_size=21):\n",
    "        super().__init__()\n",
    "#         self.pos = torch.arange(max_len)\n",
    "        self.pos = torch.arange(max_len).to(device)\n",
    "        #pos = torch.arange(max_len)\n",
    "        #self.register_buffer('pos', pos)\n",
    "        self.tok_embedding = nn.Embedding(voc_size, embed_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_len, embed_dim).to(device)\n",
    "    def forward(self, x):\n",
    "        return self.tok_embedding(x) + self.pos_embedding(self.pos)\n",
    "\n",
    "class AttenCaldX(nn.Module):\n",
    "    def __init__(self, embed_dim=16, num_heads=4, ff_dim=64, rate=0.1, max_len=12):\n",
    "        super().__init__()\n",
    "        self.emb = TokAndPosEmbedding(embed_dim, max_len, 21)\n",
    "        self.encoder1 = Encoder(embed_dim, num_heads, ff_dim, rate)\n",
    "        self.dropout1 = nn.Dropout(rate)\n",
    "        self.encoder2 = Encoder(embed_dim, num_heads, ff_dim, rate)\n",
    "        self.dropout2 = nn.Dropout(rate)\n",
    "        self.dropout3 = nn.Dropout(rate)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(embed_dim*2, 64)\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.emb(x)\n",
    "        x = self.encoder1(x)\n",
    "        x = self.dropout1(x)\n",
    "        y = self.encoder2(x)\n",
    "        y = self.dropout2(y)\n",
    "        #out = x + y\n",
    "        out = torch.concat([x,y], dim=2)\n",
    "        out = out.permute(0,2,1)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = self.dropout3(out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a2685",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################  model ##########################\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        # Initializing model components\n",
    "        self.pep_extractor = AttenCaldX()\n",
    "        self.hla_extractor = ModelLSTMAttention()\n",
    "\n",
    "        # Defining convolutional layers\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(2,1)),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 1)),\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(1,4)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 1)),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(1,4)),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "        )\n",
    "\n",
    "        # Defining fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(1792, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.4),\n",
    "            nn.Linear(100, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, pep, hla_seq, hla_len):\n",
    "        # Extracting features\n",
    "        output1 = self.pep_extractor(pep)\n",
    "        output2 = self.hla_extractor(hla_seq, hla_len)\n",
    "        # Concatenating features\n",
    "        x = torch.cat((output1.unsqueeze(1), output2.unsqueeze(1)), dim=1)\n",
    "        x = x.unsqueeze(1)  # Adding a dimension as channel\n",
    "        # Convolutional layers\n",
    "        x = self.conv_layers(x)\n",
    "        # Flattening features\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Fully connected layers\n",
    "        x = self.fc_layers(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8366eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HLADataset(Dataset):\n",
    "    def __init__(self, peptide, hla,lengths, label):\n",
    "        self.peptide = peptide\n",
    "        self.hla = hla\n",
    "        self.label = label\n",
    "        self.lengths=lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.peptide[i], self.hla[i], self.lengths[i],self.label[i]\n",
    "\n",
    "class testDataset(Dataset):\n",
    "    def __init__(self, peptide, hla,lengths):\n",
    "        self.peptide = peptide\n",
    "        self.hla = hla\n",
    "       \n",
    "        self.lengths=lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.peptide.size(0)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.peptide[i], self.hla[i], self.lengths[i]\n",
    "\n",
    "\n",
    "#Learning rate scheduling\n",
    "def adjust_learning_rate(epoch):\n",
    "    if epoch < 100:\n",
    "      return 0.0001\n",
    "    elif epoch < 200:\n",
    "      return 0.00005\n",
    "    elif epoch < 250:\n",
    "      return 0.00001\n",
    "    else:\n",
    "      return 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c755d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 加载HLA数据集\n",
    "def load_hla_dataframe(fname):\n",
    "    df = pd.read_table(fname)\n",
    "    \n",
    "    # remove peptides with ambiguous symbols: X, B\n",
    "    df = df[df.Peptide.str.contains('X|B') == False]\n",
    "    \n",
    "    return df\n",
    "def get_hla_subtype(df, min_len=9, max_len=12):\n",
    "    df1 = df[\n",
    "             (df['Peptide'].str.len() >= min_len) &\n",
    "             (df['Peptide'].str.len() <= max_len)]\n",
    "    return df1\n",
    "\n",
    "\n",
    "\n",
    "def vectorize_peps(peps, max_len=12):\n",
    "    num_pep = len(peps)\n",
    "    X = np.zeros((num_pep, max_len), dtype=np.int32)\n",
    "    for i in range(num_pep):\n",
    "        aa_code_seq = [aa_dict[aa] for aa in peps[i]]\n",
    "        pep_len = len(aa_code_seq)\n",
    "        assert pep_len <= max_len\n",
    "        X[i, max_len-pep_len:]=np.array(aa_code_seq)\n",
    "        pass\n",
    "    return np.array(X, dtype=np.int32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(y_labels, y_preds, cutoff=0.5, digit=4):\n",
    "    if (cutoff<=0) | (cutoff>=1):\n",
    "        fpr, tpr, threshold = roc_curve(y_labels, y_preds)\n",
    "        cutoff = sorted(list(zip(np.abs(tpr-fpr), threshold)), key=lambda i: i[0], reverse=True)[0][1]\n",
    "        pass\n",
    "    spearman_corr, _ = spearmanr(y_labels, y_preds)\n",
    "    y_pred_labels = np.array([1. if p >= cutoff else 0. for p in y_preds])\n",
    "    Accuracy = accuracy_score(y_labels, y_pred_labels) # \n",
    "    #Precision = precision_score(y_labels, y_pred_labels) # \n",
    "    Recall = recall_score(y_labels, y_pred_labels) # \n",
    "    Specificity = recall_score(1-y_labels, 1-y_pred_labels) # \n",
    "    F1 = f1_score(y_labels, y_pred_labels) # \n",
    "    AUC = roc_auc_score(y_labels, y_preds) # AUC\n",
    "    return {'Accuracy':    np.round(Accuracy,    digit),\n",
    "            # 'Precision':   np.round(Precision,   digit),\n",
    "            'Sensitivity': np.round(Recall,      digit),\n",
    "            'Specificity': np.round(Specificity, digit),\n",
    "            'Threshold':   np.round(cutoff,      digit),\n",
    "            #'F1':          np.round(F1,          digit),\n",
    "            'AUC':         np.round(AUC,         digit),\n",
    "            'SRCC':         np.round(spearman_corr,         digit)\n",
    "           }\n",
    "\n",
    "def evaluate(model, X,z,l, cutoff=.5):\n",
    "    (X,z,l) = (X.to(device), z.to(device),l.to(device))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # y_labels = y.squeeze()\n",
    "        y_preds = torch.sigmoid(model(X,z,l)).flatten().detach()\n",
    "        return y_preds\n",
    "def evaluate_model(model,lable_test,test_loader,cutoff=.5):\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        all_y_preds= []\n",
    "    # 迭代text_loader\n",
    "        for pep,hla,hlen  in test_loader: \n",
    "            \n",
    "            y_pred_batch= evaluate(model, pep,hla,hlen)\n",
    "            \n",
    "            all_y_preds.append(torch.tensor(y_pred_batch))\n",
    "            \n",
    "        all_y_preds = torch.cat(all_y_preds).cpu().numpy()\n",
    "        \n",
    "    lable_test=lable_test.cpu().numpy()\n",
    "    \n",
    "    return compute_metrics(lable_test,all_y_preds)\n",
    "\n",
    "def data_processing(train_data_path):\n",
    "    # Load and process the data\n",
    "    df_data = load_hla_dataframe(train_data_path)\n",
    "    df_data = get_hla_subtype(df_data)\n",
    "\n",
    "    Peptide = vectorize_peps(list(df_data.Peptide))\n",
    "    lable = np.array(\n",
    "            [1 if x==1 else 0 for x in df_data.BindingCategory], dtype=np.float32).reshape(-1,1)\n",
    "    print(lable.shape)\n",
    "    print(Peptide.shape)\n",
    "\n",
    "    HLA_sequence=[]\n",
    "    hla=df_data.HLA\n",
    "    HLA_sequence=HLA_seq_list(hla)\n",
    "    lengths_HLA_sequence= [len(sequence) for sequence in HLA_sequence]\n",
    "    HLA_seq=enc_list_bl_max_len(HLA_sequence, pca15_aaidx, 366)\n",
    "    Peptide = torch.tensor(Peptide)\n",
    "\n",
    "    lengths_HLA_sequence = torch.tensor(lengths_HLA_sequence)\n",
    "\n",
    "    HLA_seq = torch.tensor(HLA_seq)\n",
    "\n",
    "    lable = torch.tensor(lable)\n",
    "\n",
    "    return Peptide,HLA_seq,lengths_HLA_sequence,lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca91087-8e05-4726-aab0-ea5fd1bb41f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(Peptide, HLA_seq, lengths_HLA_sequence, lable, NUM_FOLDS=5,device = \"cuda\", BATCH_SIZE = 64):\n",
    "    # Create a K-Fold object for dataset splitting\n",
    "    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=1234)\n",
    "\n",
    "    # Initialize objects to store training and testing losses for each fold\n",
    "    fold_train_losses = []\n",
    "    fold_test_losses = []\n",
    "\n",
    "    # Perform training and testing for each fold in five-fold cross-validation\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(Peptide)):\n",
    "        print(f\"Fold {fold_idx + 1}/{NUM_FOLDS}\")\n",
    "\n",
    "        # Split the dataset according to the current fold\n",
    "        Peptide_train, Peptide_test = Peptide[train_index], Peptide[test_index]\n",
    "        hla_train, hla_test = HLA_seq[train_index], HLA_seq[test_index]\n",
    "        lengths_train, lengths_test = lengths_HLA_sequence[train_index], lengths_HLA_sequence[test_index]\n",
    "        lable_train, lable_test = lable[train_index], lable[test_index]\n",
    "\n",
    "        # Further split the training set into training and validation sets\n",
    "        Pep_train, Pep_valid, HLA_train, HLA_valid, len_train, len_valid, lab_train, lab_valid = train_test_split(\n",
    "            Peptide_train, hla_train, lengths_train, lable_train, test_size=0.2, random_state=2024)\n",
    "\n",
    "        # Create DataLoader objects for training, validation, and testing sets\n",
    "        train_data = HLADataset(Pep_train, HLA_train, len_train, lab_train)\n",
    "        valid_data = HLADataset(Pep_valid, HLA_valid, len_valid, lab_valid)\n",
    "        test_data = testDataset(Peptide_test, hla_test, lengths_test)\n",
    "\n",
    "\n",
    "        train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\n",
    "        valid_loader = DataLoader(valid_data, shuffle=False, batch_size=BATCH_SIZE)\n",
    "        test_loader = DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "        # Calculate the number of iterations per epoch for training and validation\n",
    "        trainSteps = len(train_data) // BATCH_SIZE\n",
    "        validSteps = len(valid_data) // BATCH_SIZE\n",
    "\n",
    "        # Initialize the model and optimizer\n",
    "        model = Model().to(device)\n",
    "        loss_fn = nn.BCEWithLogitsLoss()  # Loss function\n",
    "        cur_lr = 0.0001\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=cur_lr)  # Optimizer\n",
    "\n",
    "        # Initialize objects to store training process losses\n",
    "        H = {\"train_loss\": [], \"test_loss\": []}\n",
    "\n",
    "        # Total number of epochs for training\n",
    "        NUM_EPOCHS = 300\n",
    "        print(\"[INFO] training the network...\")\n",
    "        startTime = time.time()\n",
    "        for e in tqdm(range(NUM_EPOCHS)):\n",
    "            lr = adjust_learning_rate(e)\n",
    "            if cur_lr != lr:\n",
    "                cur_lr = lr\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=cur_lr)  # Adjust learning rate\n",
    "\n",
    "            # Set model to training mode\n",
    "            model.train()\n",
    "\n",
    "            # Initialize total training and validation losses\n",
    "            totalTrainLoss = 0\n",
    "            totalVaildLoss = 0\n",
    "\n",
    "            # Iterate over training dataset\n",
    "            for (i, (x, z, l, y)) in enumerate(train_loader):\n",
    "                (x, z, l, y) = (x.to(device), z.to(device), l.to(device), y.to(device))\n",
    "\n",
    "                # Forward pass and compute loss\n",
    "                pred = model(x, z, l)\n",
    "                y = y.float()\n",
    "                loss = loss_fn(pred, y)\n",
    "\n",
    "                # Zero gradients, backward pass, and update parameters\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Add loss to total training loss\n",
    "                totalTrainLoss += loss\n",
    "\n",
    "            # Disable gradient computation\n",
    "            with torch.no_grad():\n",
    "                # Set model to evaluation mode\n",
    "                model.eval()\n",
    "\n",
    "                # Iterate over validation dataset\n",
    "                for (x1, z1, l1, y1) in valid_loader:\n",
    "                    (x1, z1, l1, y1) = (x1.to(device), z1.to(device), l1.to(device), y1.to(device))\n",
    "                    # Predict and compute loss\n",
    "                    pred1 = model(x1, z1, l1)\n",
    "                    y1 = y1.float()\n",
    "                    totalVaildLoss += loss_fn(pred1, y1)\n",
    "\n",
    "            # Compute average training and validation losses\n",
    "            avgTrainLoss = totalTrainLoss / trainSteps\n",
    "            avgvalidLoss = totalVaildLoss / validSteps\n",
    "\n",
    "            # Update training history\n",
    "            H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "            H[\"test_loss\"].append(avgvalidLoss.cpu().detach().numpy())\n",
    "\n",
    "            # Print loss information for the current epoch\n",
    "            print(\"[INFO] EPOCH: {}/{}, {:.6f}\".format(e + 1, NUM_EPOCHS, cur_lr))\n",
    "            print(\"Train loss: {:.4f}, Test loss: {:.4f}\".format(avgTrainLoss, avgvalidLoss))\n",
    "\n",
    "        # Display total training time\n",
    "        endTime = time.time()\n",
    "        print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))\n",
    "\n",
    "        # Add current fold's training and testing losses to the lists\n",
    "        fold_train_losses.append(H[\"train_loss\"])\n",
    "        fold_test_losses.append(H[\"test_loss\"])\n",
    "        print(\"Testing results\")\n",
    "        print(evaluate_model(model, lable_test, test_loader, 0.5))\n",
    "        filename = f\"../model/model(Five-fold cross-validation)/model_fold_{fold_idx + 1}.pth\"  # Create filename using f-string\n",
    "        torch.save(model.state_dict(), filename)\n",
    "\n",
    "    # Calculate average training and testing losses for five-fold cross-validation\n",
    "    avg_train_losses = np.mean(np.array(fold_train_losses), axis=0)\n",
    "    avg_test_losses = np.mean(np.array(fold_test_losses), axis=0)\n",
    "\n",
    "    # Print average training and testing losses\n",
    "    print(\"Average train loss:\", avg_train_losses[-1])\n",
    "    print(\"Average test loss:\", avg_test_losses[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dccdb3a-0f24-427f-aabf-dff5cb41e148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = \"cuda\"\n",
    "# Path to the training data\n",
    "train_data_path = '../data/proteins.txt'\n",
    "# Loss function\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "# Load the data and do a five-fold cross-validation\n",
    "Peptide,HLA_seq,lengths_HLA_sequence,lable=data_processing(train_data_path)\n",
    "k_fold_cross_validation(Peptide,HLA_seq,lengths_HLA_sequence,lable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df5193-c777-438a-8c11-4a987f91b905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
